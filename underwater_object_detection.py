# -*- coding: utf-8 -*-
"""Underwater_Object_Detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1F20_JXE8W0TESiVkb2eMyvNPzkpihZ-r

# Underwater_Object_Detection_YOLOv5-pyTorch
 - 本版本將整合colab及本地運行版本
---
## Modules Import And CUDA Check
"""
import os, yaml
from IPython import get_ipython

def universal_cmd(cmd=""):
    try:
        try:
            get_ipython().magic("%"+cmd)
        except :
            get_ipython().system(cmd)
    except:
        os.system(cmd)



# Commented out IPython magic to ensure Python compatibility.
print("-"*30+"\n ### Modules import")
print("Detect Google Colab Environment...")
isColab = True
try:
    from google.colab import drive
    drive.mount('/content/drive')
except ModuleNotFoundError as e:
    print("{},it's not in Colab.".format(e))
    isColab = False
print(" - Number of Classes ------------ {}".format(isColab)+'\n')
print("import torch")

universal_cmd("conda install torch")
import torch
print(" - Torch CUDA available --------- {}".format(torch.cuda.is_available()))
print(">>> "+'Using torch %s %s'%(
    torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'
)+'\n')
print("pylab inline (jupyter command)")
# %pylab inline
print("\nimport os, yaml")

print("\nimport IPython tool:")
print("Image: for displaying images")
print("register_line_cell_magic: ")
from IPython.display import Image  # for displaying images
from IPython.core.magic import register_line_cell_magic
print("\nModules import completed...")

print(" - Current Directory ------------"+"\n>>> "+os.getcwd())

#nvidia-smi

# Commented out IPython magic to ensure Python compatibility.
print(yaml.__version__) # need to >= 5.0
'''
if float(yaml.__version__) < 5.0:
     universal_cmd("pip -y uninstall PyYAML") # y
     universal_cmd("pip install -U PyYAML") # 有要重跑就重跑
universal_cmd("pip uninstall utils")
universal_cmd("pip install python_utils")
'''
"""## Environment Repo Create And Install Depencies
 - If it's first time using, please run first two command lines to set up repo. and package.
"""

# Environ Set
if isColab:
#    universal_cmd("unzip ./yolov5.zip -d /content")
#    universal_cmd('rm -r "yolov5"')
#    universal_cmd('git clone https://github.com/ultralytics/yolov5')
    universal_cmd('pip install -U -r yolov5/requirements.txt --user') # 不用重跑
#universal_cmd('cd ./yolov5')
print(" - Current Directory ------------"+"\n>>> "+os.getcwd())

"""## DataSet Preparation
 - Mainly for colab feature Google Drive
"""
'''
ArchivedFilesPath = '/content/drive/MyDrive/'
ArchivedFilesName = 'underwater_dataset.zip' # roboflow的匯出檔，內含'data.yaml', 'test', 'valid', 'train'，先丟到雲端
DisarchivedFolder = ArchivedFilesName.replace('.zip', '')
DestinationPath = '/content/'

if isColab:
    universal_cmd("unzip {} -d {}".format(
        (ArchivedFilesPath+ArchivedFilesName), (DestinationPath+DisarchivedFolder))
    )
    for i in ['data.yaml', 'test', 'valid', 'train']:
        universal_cmd('mv ./{}/underwater_dataset/{} /content/yolov5/'.format(DisarchivedFolder ,i))
    for i in [DisarchivedFolder, '__MACOSX']:
        universal_cmd('rm -r ./{}'.format(i))
    
#    universal_cmd("cp ./drive/MyDrive/detect-modify-v2.4.py ./yolov5")
#    [ universal_cmd("mv {}{}/{}/{} {}".format(
#        DestinationPath, DisarchivedFolder, DisarchivedFolder, i, "/content/yolov5")) 
#    for i in ['data.yaml', 'test', 'valid', 'train'] ]
'''
universal_cmd("ls")
# universal_cmd("cd yolov5")

"""## Data Preparation
 - It requires data set unzip at the folder "yolov5"
"""

#customize iPython writefile so we can write variables
'''
@register_line_cell_magic
def writetemplate(line, cell):
    with open(line, 'w') as f:
        f.write(cell.format(**globals()))
'''
def dataSetCheck():
    currentdir = os.getcwd()
    print(" - Current Directory ------------ ")
    print(">>> "+currentdir)
    
    print(" - File Checking ---------------- ")
    '''if not 'yolov5' in currentdir[-10:]:
        os.chdir('yolov5')
        print("Change dir to './yolov5'") '''
    for filePath in [
        "./data.yaml", "./test/",
        "./valid/", "./train/"  ]:
        if os.path.exists(filePath):
            print("'{}' confirm.".format(filePath))
        else:
            print("''{}'' no found".format(filePath))
            return False
    print("The data was ready.")
    return True

def fileprint(txtfile):
    print("-"*15+" File Name "+"-"*15)
    print(">>> "+txtfile)
    print("-"*15+" File Init "+"-"*15)
    with open(txtfile, 'r') as openfile:
        linelist = list(openfile)
        [ print(
            "{}> ".format((str(i)+" ").ljust(4,' ')+'>')+
            linelist[i].replace("\n", "")
        )  for i in range(len(linelist)) ]
    print("-"*15+" File End  "+"-"*15)
        
def labelclassCheck():
    with open(r'data.yaml') as file:
        # The FullLoader parameter handles the conversion from YAML
        # scalar values to Python the dictionary format
        labels_list = yaml.load(file, Loader=yaml.FullLoader)
        label_names = labels_list['names']
    print(" - Number of Classes ------------ {}".format(num_classes))
    print(" - Label of Classes ------------- ")
    [print(">>> "+i) for i in label_names]
    return labels_list
  
# Ready Check ---------------------------------------------
'''
def readyCheck():
    print('Using torch %s %s' % (
    torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'
))
    print("\n"+"-"*60+"\n ### DataSet Checking") # ------------------------
    if not dataSetCheck():
        raise KeyboardInterrupt("Files no found, pausing the script.")
    print("\n"+"-"*60+"\n ### 'data.yaml'")
    fileprint('data.yaml')
    with open("data.yaml", 'r') as stream:
        globals()['num_classes'] = str(yaml.safe_load(stream)['nc'])
    print("\n"+"-"*60+"\n ### YAML processing")

    print("\n"+"-"*60+"\n ### Check 'yolov5s.yaml' Setting")
    #this is the model configuration we will use for our tutorial 
    # yolov5s.yaml contains the configuration of neural network required for training.
    fileprint("./models/yolov5s.yaml")
    
    data_yaml_temp = labelclassCheck()
    data_yaml_temp['train'] = data_yaml_temp['train'].replace("..", ".")
    data_yaml_temp['val'] = data_yaml_temp['val'].replace("..", ".")
    # print(data_yaml_temp)
    with open('data.yaml', 'w+') as file:
        yaml.dump(data_yaml_temp, file)
        
    fileprint('data.yaml')
'''    
# ---------------------------------------------------------
# define number of classes based on YAML
# data.yaml contains the information about number of classes and their labels required for this project

#readyCheck()

"""## Create Custome YOLOv5 Setting"""

# Below we are changing the configuration so that it becomes compatible to number of classes required in this project
yolo_set_text = ('''
# parameters
nc: {num_classes}  # number of classes  # CHANGED HERE
depth_multiple: 0.33  # model depth multiple
width_multiple: 0.50  # layer channel multiple

# anchors
anchors:
  - [10,13, 16,30, 33,23]  # P3/8
  - [30,61, 62,45, 59,119]  # P4/16
  - [116,90, 156,198, 373,326]  # P5/32

# YOLOv5 backbone
backbone:
  # [from, number, module, args]
  [[-1, 1, Focus, [64, 3]],  # 0-P1/2
   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4
   [-1, 3, BottleneckCSP, [128]],
   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8
   [-1, 9, BottleneckCSP, [256]],
   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16
   [-1, 9, BottleneckCSP, [512]],
   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32
   [-1, 1, SPP, [1024, [5, 9, 13]]],
   [-1, 3, BottleneckCSP, [1024, False]],  # 9
  ]

# YOLOv5 head
head:
  [[-1, 1, Conv, [512, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 6], 1, Concat, [1]],  # cat backbone P4
   [-1, 3, BottleneckCSP, [512, False]],  # 13

   [-1, 1, Conv, [256, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 4], 1, Concat, [1]],  # cat backbone P3
   [-1, 3, BottleneckCSP, [256, False]],  # 17 (P3/8-small)

   [-1, 1, Conv, [256, 3, 2]],
   [[-1, 14], 1, Concat, [1]],  # cat head P4
   [-1, 3, BottleneckCSP, [512, False]],  # 20 (P4/16-medium)

   [-1, 1, Conv, [512, 3, 2]],
   [[-1, 10], 1, Concat, [1]],  # cat head P5
   [-1, 3, BottleneckCSP, [1024, False]],  # 23 (P5/32-large)

   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)
  ]
''')

with open(
    "./models/custom_yolov5s.yaml", "w+", encoding='utf-8'
) as testfile:
    print(yolo_set_text, file=testfile)
fileprint("./models/custom_yolov5s.yaml")

"""---
## Main
"""

#readyCheck()

# Commented out IPython magic to ensure Python compatibility.
# %%time
# # train yolov5s on Aquarium object detection data for 100 epochs [aroung 1000 epochs for better training and result]
# # NOTE: All the images are already pre-processed to 416 x 416 size.
# # We will be training for 100 epoch (increase it for better result) with batch size of 80
# # data.yaml a|lso contains the information about location of Train and Validation Data. That's how you get the train data.
# # the training also requires the configuration of neural network, which is in custom_yolov5s.yaml
# # weights will be by-default stored at /content/yolov5/runs/exp2/weights/best.pt
# # time its performance
# 
universal_cmd(
    "python3 ./train.py "+
    "--img 240 --batch 100 --epochs 100 "+
    "--data data.yaml --cfg ./models/custom_yolov5s.yaml "+
    "--weights '' "+
    "--name shot"
)

#import torch
# torch.cuda.empty_cache()
print(torch.cuda.memory_summary(device=None, abbreviated=False))

"""---
## After
 - Result 
"""

# Commented out IPython magic to ensure Python compatibility.
# Start tensorboard
# Launch after you have started training to all the graphs needed for inspection
# logs save in the folder "runs"
# %load_ext tensorboard
# %tensorboard --logdir /content/yolov5/runs

# use the best weights!
# Final weights will be by-default stored at /content/yolov5/runs/train/exp2/weights/best.pt
universal_cmd(
    "python detect-modify-v2.py "+
    "--img 512 "+"--conf 0.4 "+"--source ./test/images "+
    "--weights ./runs/train/shot4/weights/best.pt"
)

universal_cmd("zip -r ../result.zip ./runs")
# universal_cmd("cp ../result.zip ../drive/MyDrive")

#display inference on ALL test images
#this looks much better with longer training above

import glob
from IPython.display import Image, display

for imageName in glob.glob('./runs/detect/exp/*.jpg'): #assuming JPG
    display(Image(filename=imageName))
    print("\n")
